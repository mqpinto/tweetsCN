{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/mac/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "from textblob import TextBlob as tb\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_data = read_csv(\"en_dataset.csv\", encoding = \"ISO-8859-1\", sep=';', low_memory=False)\n",
    "\n",
    "nn_data = raw_data.loc[:, 'Index':'Time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define transform_raw_text to make all transformations to tweet text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_raw_text(text):\n",
    "    text = re.sub(r'\\B\\#[^\\s]+\\b\\s*', '', text) # Remove all hashtags\n",
    "    text = re.sub(r'\\B\\@[^\\s]+\\b\\s*', '', text) # Remove all people identifications\n",
    "    text = ' '.join(nltk.word_tokenize(text))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define function to print info about data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_report(df):\n",
    "    neg_rows = len(df.loc[nn_data['Polarity'] < 0])\n",
    "    positive_rows = len(df.loc[nn_data['Polarity'] > 0])\n",
    "    total_rows = len(df)\n",
    "    neutral_rows = total_rows - neg_rows - positive_rows\n",
    "\n",
    "    print('Total: {0}; Neutral: {1}; Positive: {2}; Negative: {3}'.format(str(total_rows),str(neutral_rows),str(positive_rows),str(neg_rows)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate Polarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0|1000|2000|3000|4000|5000|6000|7000|8000|9000|10000|11000|12000|13000|14000|15000|16000|17000|18000|19000|20000|21000|22000|23000|24000|25000|26000|27000|28000|29000|30000|31000|32000|33000|34000|35000|36000|37000|38000|39000|40000|41000|42000|43000|44000|45000|46000|47000|48000|49000|50000|51000|52000|53000|54000|55000|56000|57000|58000|59000|60000|61000|62000|63000|64000|65000|66000|67000|68000|69000|70000|71000|72000|73000|74000|75000|76000|77000|78000|79000|80000|81000|82000|83000|84000|85000|86000|87000|88000|89000|90000|91000|92000|93000|94000|95000|96000|97000|98000|99000|100000|101000|102000|103000|104000|105000|106000|107000|108000|109000|110000|111000|112000|113000|114000|115000|116000|117000|118000|119000|120000|121000|122000|123000|124000|125000|126000|127000|128000|129000|130000|131000|132000|133000|134000|135000|136000|137000|138000|139000|140000|141000|142000|143000|144000|145000|146000|147000|148000|149000|150000|151000|152000|153000|154000|155000|156000|157000|158000|159000|160000|161000|162000|163000|164000|165000|166000|167000|168000|169000|170000|171000|172000|173000|174000|175000|176000|177000|178000|179000|180000|181000|182000|183000|184000|185000|186000|187000|188000|189000|190000|191000|192000|193000|194000|195000|196000|197000|198000|199000|200000|201000|202000|203000|204000|205000|206000|207000|208000|209000|210000|211000|212000|213000|214000|215000|216000|217000|218000|219000|220000|221000|222000|223000|224000|225000|226000|227000|228000|229000|230000|231000|232000|233000|234000|235000|236000|237000|238000|239000|240000|241000|242000|243000|244000|245000|246000|247000|248000|249000|250000|251000|252000|253000|254000|255000|256000|257000|258000|259000|260000|261000|262000|263000|264000|265000|266000|267000|268000|269000|270000|271000|272000|273000|274000|275000|276000|277000|278000|279000|280000|281000|282000|283000|284000|285000|286000|287000|288000|289000|290000|291000|292000|293000|294000|295000|296000|297000|298000|299000|300000|301000|302000|303000|304000|305000|306000|307000|308000|309000|310000|311000|312000|313000|314000|315000|316000|317000|318000|319000|320000|321000|322000|323000|324000|325000|326000|327000|328000|329000|330000|331000|332000|333000|334000|335000|336000|337000|338000|339000|340000|341000|342000|343000|344000|345000|346000|347000|348000|349000|350000|351000|352000|353000|354000|355000|356000|357000|358000|359000|360000|361000|362000|363000|364000|365000|366000|367000|368000|369000|370000|371000|372000|373000|374000|375000|376000|377000|378000|"
     ]
    }
   ],
   "source": [
    "polarities = []\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for index, row in nn_data.iterrows():\n",
    "    text = row['TextPost']\n",
    "    text = transform_raw_text(text)\n",
    "    res = analyzer.polarity_scores(text)\n",
    "    polarities.append(res['compound'])\n",
    "    if index % 1000 == 0:\n",
    "        print(str(index), end='|') \n",
    "\n",
    "nn_data['Polarity'] = polarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show main results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 378407; Neutral: 216975; Positive: 110756; Negative: 50676\n"
     ]
    }
   ],
   "source": [
    "df_report(nn_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export dataset to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_data.to_csv('first_evaluation_results.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fnnd = nn_data.query('Polarity  >= 0.2 | Polarity <= -0.2 | Polarity == 0')\n",
    "fnnd = nn_data.loc[(nn_data['Polarity'] >= 0.2) | (nn_data['Polarity'] <= -0.2) | (nn_data['Polarity'] == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 362673; Neutral: 216975; Positive: 102009; Negative: 43689\n"
     ]
    }
   ],
   "source": [
    "df_report(fnnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnnd.to_csv('first_evaluation_results_f0.2.csv', sep=';', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
